algo: dqn_stack_action
env: LunarLander-v2
lr: 1e-2
n_episodes: 10000
hidden_sizes: '[64, 64, 32]'
ep_thresh: 0.1
batch_size: 64
render: False
device: cuda:0
discount_factor: 0.999
reset_step: 25
trained_model_path: ./algorithms/dqn/trained_models/my_dqn.pth
test: False
replay_mem_size: 100000

